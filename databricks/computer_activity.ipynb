{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fa78404b-8eb8-452d-970a-5d69631c02fe",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Import Libraries and Start Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "22611f8a-c63b-4551-afe4-6e516500626c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession, DataFrame, functions as F\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import col, year, month, dayofmonth, hour, rand, from_unixtime, date_format, floor, expr\n",
    "from pyspark.sql.types import DoubleType\n",
    "from functools import reduce\n",
    "import math\n",
    "\n",
    "# Initialize the Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"S3_JSON_Analysis\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f755e227-314a-465f-87f0-3880402e4ad4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Read data from S3 bucket and extract the year, month, day and hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ad5ba42d-b729-409c-bf6f-2b9dde9b3c20",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- activity_type: string (nullable = true)\n |-- app_name: string (nullable = true)\n |-- button: string (nullable = true)\n |-- idle_duration: double (nullable = true)\n |-- timestamp: string (nullable = true)\n |-- window_name: string (nullable = true)\n |-- word: string (nullable = true)\n |-- word_length: long (nullable = true)\n |-- x: double (nullable = true)\n |-- y: double (nullable = true)\n |-- year: integer (nullable = true)\n |-- month: integer (nullable = true)\n |-- day: integer (nullable = true)\n |-- hour: integer (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "# Adjust the S3 path to match the root of your partitioned data\n",
    "s3_path = \"s3://computeractivity/\"\n",
    "\n",
    "# Load data with Spark, using pathGlobFilter for partition columns\n",
    "df = (\n",
    "    spark.read.option(\"basePath\", s3_path)  # Sets base path for partition discovery\n",
    "          .json(s3_path + \"activity_type=*/year=*/month=*/day=*/hour=*\")\n",
    ")\n",
    "\n",
    "# Now, Spark should recognize activity_type, year, month, day, and hour as columns\n",
    "df.printSchema()  # Confirm schema includes the partition columns\n",
    "\n",
    "# Extract and cast partition columns\n",
    "df = df.withColumn(\"year\", col(\"year\").cast(\"int\")) \\\n",
    "       .withColumn(\"month\", col(\"month\").cast(\"int\")) \\\n",
    "       .withColumn(\"day\", col(\"day\").cast(\"int\")) \\\n",
    "       .withColumn(\"hour\", col(\"hour\").cast(\"int\")) \\\n",
    "       .withColumn(\"activity_type\", col(\"activity_type\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "576cffea-c9a8-4310-a419-34b404e96287",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-----+\n|           app_name|count|\n+-------------------+-----+\n|              Slack|  101|\n|           Terminal|  160|\n|AppleScript Utility|   64|\n|      Google Chrome|  759|\n|               main|    1|\n|    Keychain Access|    1|\n|    System Settings|   12|\n|             Finder|    2|\n|  Microsoft Outlook|    2|\n|             Python|    2|\n+-------------------+-----+\n\n"
     ]
    }
   ],
   "source": [
    "app_change = df.filter(\"activity_type = 'app_change'\")\n",
    "\n",
    "app_counts = app_change.groupBy(\"app_name\").count()\n",
    "app_counts.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4fc15a7d-1538-4c4a-94e5-dfc63d67c086",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-------------+------+-------------+--------------------+--------------------+----+-----------+----+----+----+-----+---+----+----------+------------+\n|activity_type|     app_name|button|idle_duration|           timestamp|         window_name|word|word_length|   x|   y|year|month|day|hour|   seconds|milliseconds|\n+-------------+-------------+------+-------------+--------------------+--------------------+----+-----------+----+----+----+-----+---+----+----------+------------+\n|   app_change|     Terminal|  NULL|         NULL|2024-10-26T17:28:...|willbutler — /Use...|NULL|       NULL|NULL|NULL|2024|   10| 26|  16|1729963732|         809|\n|   app_change|     Terminal|  NULL|         NULL|2024-10-26T17:28:...|willbutler — will...|NULL|       NULL|NULL|NULL|2024|   10| 26|  16|1729963738|         136|\n|   app_change|     Terminal|  NULL|         NULL|2024-10-26T17:29:...|willbutler — will...|NULL|       NULL|NULL|NULL|2024|   10| 26|  16|1729963741|         252|\n|   app_change|     Terminal|  NULL|         NULL|2024-10-26T17:29:...|willbutler — /Use...|NULL|       NULL|NULL|NULL|2024|   10| 26|  16|1729963743|         348|\n|   app_change|     Terminal|  NULL|         NULL|2024-10-26T17:29:...|willbutler — will...|NULL|       NULL|NULL|NULL|2024|   10| 26|  16|1729963748|         541|\n|   app_change|     Terminal|  NULL|         NULL|2024-10-26T17:29:...|willbutler — will...|NULL|       NULL|NULL|NULL|2024|   10| 26|  16|1729963751|         459|\n|   app_change|     Terminal|  NULL|         NULL|2024-10-26T17:29:...|main — bash ◂ -zs...|NULL|       NULL|NULL|NULL|2024|   10| 26|  16|1729963752|         565|\n|   app_change|     Terminal|  NULL|         NULL|2024-10-26T17:29:...|LaunchAgents — wi...|NULL|       NULL|NULL|NULL|2024|   10| 26|  16|1729963754|         621|\n|   app_change|     Terminal|  NULL|         NULL|2024-10-26T17:29:...|LaunchAgents — wi...|NULL|       NULL|NULL|NULL|2024|   10| 26|  16|1729963756|         800|\n|   app_change|     Terminal|  NULL|         NULL|2024-10-26T17:29:...|LaunchAgents — wi...|NULL|       NULL|NULL|NULL|2024|   10| 26|  16|1729963757|         934|\n|   app_change|     Terminal|  NULL|         NULL|2024-10-26T17:29:...|LaunchAgents — na...|NULL|       NULL|NULL|NULL|2024|   10| 26|  16|1729963760|         103|\n|   app_change|     Terminal|  NULL|         NULL|2024-10-26T17:29:...|LaunchAgents — na...|NULL|       NULL|NULL|NULL|2024|   10| 26|  16|1729963761|         565|\n|   app_change|     Terminal|  NULL|         NULL|2024-10-26T17:29:...|LaunchAgents — na...|NULL|       NULL|NULL|NULL|2024|   10| 26|  16|1729963762|           4|\n|   app_change|Google Chrome|  NULL|         NULL|2024-10-26T17:29:...|Productivity Tracker|NULL|       NULL|NULL|NULL|2024|   10| 26|  16|1729963763|         183|\n|   app_change|Google Chrome|  NULL|         NULL|2024-10-26T17:29:...|Productivity Tracker|NULL|       NULL|NULL|NULL|2024|   10| 26|  16|1729963765|         330|\n|   app_change|Google Chrome|  NULL|         NULL|2024-10-26T17:29:...|Productivity Tracker|NULL|       NULL|NULL|NULL|2024|   10| 26|  16|1729963766|         968|\n|   app_change|Google Chrome|  NULL|         NULL|2024-10-26T17:29:...|Productivity Tracker|NULL|       NULL|NULL|NULL|2024|   10| 26|  16|1729963767|         353|\n|   app_change|     Terminal|  NULL|         NULL|2024-10-26T17:29:...|LaunchAgents — na...|NULL|       NULL|NULL|NULL|2024|   10| 26|  16|1729963769|         491|\n|   app_change|     Terminal|  NULL|         NULL|2024-10-26T17:29:...|LaunchAgents — na...|NULL|       NULL|NULL|NULL|2024|   10| 26|  16|1729963770|         687|\n|   app_change|     Terminal|  NULL|         NULL|2024-10-26T17:29:...|LaunchAgents — na...|NULL|       NULL|NULL|NULL|2024|   10| 26|  16|1729963772|         174|\n+-------------+-------------+------+-------------+--------------------+--------------------+----+-----------+----+----+----+-----+---+----+----------+------------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "app_change.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3cee4b0f-9860-4aa9-b954-07113ef25511",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "words_typed = df.filter(\"activity_type = 'word_completed'\")\n",
    "\n",
    "words_by_date = words_typed.groupBy(\"year\", \"month\", \"day\", \"hour\", \"minute\").agg(\n",
    "    F.count(\"*\").alias(\"words_typed\"),\n",
    "    F.avg(\"word_length\").alias(\"avg_word_length\")\n",
    ")\n",
    "words_by_date.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "797523f0-aeaa-468b-8c7b-c8a5a9526d96",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------+------+-------------+------------------+-----------+----+-----------+------------+------------+----+-----+---+----+----------+------------+--------------------+--------------------+----------+\n| activity_type|app_name|button|idle_duration|         timestamp|window_name|word|word_length|           x|           y|year|month|day|hour|   seconds|milliseconds|      timestamp_test|     timestamp_mouse|      date|\n+--------------+--------+------+-------------+------------------+-----------+----+-----------+------------+------------+----+-----+---+----+----------+------------+--------------------+--------------------+----------+\n|mouse_movement|    NULL|  NULL|         NULL|1728821618.1731782|       NULL|NULL|       NULL| 453.3203125|783.41015625|2024|   10| 13|  12|1728821618|      173178|2024-10-13T12:13:...|2024-10-13T12:13:...|2024-10-13|\n|mouse_movement|    NULL|  NULL|         NULL| 1728821618.326953|       NULL|NULL|       NULL| 453.3203125| 785.7890625|2024|   10| 13|  12|1728821618|      326952|2024-10-13T12:13:...|2024-10-13T12:13:...|2024-10-13|\n|mouse_movement|    NULL|  NULL|         NULL| 1728821618.352664|       NULL|NULL|       NULL| 453.3203125|787.15234375|2024|   10| 13|  12|1728821618|      352663|2024-10-13T12:13:...|2024-10-13T12:13:...|2024-10-13|\n|mouse_movement|    NULL|  NULL|         NULL| 1728821618.173179|       NULL|NULL|       NULL| 453.3203125|783.41015625|2024|   10| 13|  12|1728821618|      173178|2024-10-13T12:13:...|2024-10-13T12:13:...|2024-10-13|\n|mouse_movement|    NULL|  NULL|         NULL| 1728821618.378138|       NULL|NULL|       NULL| 453.3203125| 785.7890625|2024|   10| 13|  12|1728821618|      378138|2024-10-13T12:13:...|2024-10-13T12:13:...|2024-10-13|\n|mouse_movement|    NULL|  NULL|         NULL| 1728821618.377547|       NULL|NULL|       NULL| 453.3203125|787.72265625|2024|   10| 13|  12|1728821618|      377547|2024-10-13T12:13:...|2024-10-13T12:13:...|2024-10-13|\n|mouse_movement|    NULL|  NULL|         NULL|   1728821618.4006|       NULL|NULL|       NULL| 453.3203125|787.98046875|2024|   10| 13|  12|1728821618|      400599|2024-10-13T12:13:...|2024-10-13T12:13:...|2024-10-13|\n|mouse_movement|    NULL|  NULL|         NULL| 1728821618.399573|       NULL|NULL|       NULL| 453.3203125|787.15234375|2024|   10| 13|  12|1728821618|      399573|2024-10-13T12:13:...|2024-10-13T12:13:...|2024-10-13|\n|mouse_movement|    NULL|  NULL|         NULL|1728821618.4219332|       NULL|NULL|       NULL| 453.3203125|788.23828125|2024|   10| 13|  12|1728821618|      421933|2024-10-13T12:13:...|2024-10-13T12:13:...|2024-10-13|\n|mouse_movement|    NULL|  NULL|         NULL| 1728821618.425057|       NULL|NULL|       NULL| 453.3203125|787.72265625|2024|   10| 13|  12|1728821618|      425056|2024-10-13T12:13:...|2024-10-13T12:13:...|2024-10-13|\n|mouse_movement|    NULL|  NULL|         NULL| 1728821618.445018|       NULL|NULL|       NULL|453.08203125|788.23828125|2024|   10| 13|  12|1728821618|      445018|2024-10-13T12:13:...|2024-10-13T12:13:...|2024-10-13|\n|mouse_movement|    NULL|  NULL|         NULL| 1728821618.450161|       NULL|NULL|       NULL| 453.3203125|787.98046875|2024|   10| 13|  12|1728821618|      450160|2024-10-13T12:13:...|2024-10-13T12:13:...|2024-10-13|\n|mouse_movement|    NULL|  NULL|         NULL| 1728821618.466635|       NULL|NULL|       NULL| 452.8203125|788.23828125|2024|   10| 13|  12|1728821618|      466634|2024-10-13T12:13:...|2024-10-13T12:13:...|2024-10-13|\n|mouse_movement|    NULL|  NULL|         NULL| 1728821618.475542|       NULL|NULL|       NULL| 453.3203125|788.23828125|2024|   10| 13|  12|1728821618|      475542|2024-10-13T12:13:...|2024-10-13T12:13:...|2024-10-13|\n|mouse_movement|    NULL|  NULL|         NULL| 1728821618.492105|       NULL|NULL|       NULL| 452.8203125|785.85546875|2024|   10| 13|  12|1728821618|      492105|2024-10-13T12:13:...|2024-10-13T12:13:...|2024-10-13|\n|mouse_movement|    NULL|  NULL|         NULL| 1728821618.500888|       NULL|NULL|       NULL|453.08203125|788.23828125|2024|   10| 13|  12|1728821618|      500888|2024-10-13T12:13:...|2024-10-13T12:13:...|2024-10-13|\n|mouse_movement|    NULL|  NULL|         NULL| 1728821618.516033|       NULL|NULL|       NULL| 452.8203125|779.08203125|2024|   10| 13|  12|1728821618|      516032|2024-10-13T12:13:...|2024-10-13T12:13:...|2024-10-13|\n|mouse_movement|    NULL|  NULL|         NULL| 1728821618.534318|       NULL|NULL|       NULL| 452.8203125|788.23828125|2024|   10| 13|  12|1728821618|      534317|2024-10-13T12:13:...|2024-10-13T12:13:...|2024-10-13|\n|mouse_movement|    NULL|  NULL|         NULL|  1728821618.53982|       NULL|NULL|       NULL| 452.8203125| 768.2578125|2024|   10| 13|  12|1728821618|      539819|2024-10-13T12:13:...|2024-10-13T12:13:...|2024-10-13|\n|mouse_movement|    NULL|  NULL|         NULL|1728821618.5625112|       NULL|NULL|       NULL| 452.8203125|785.85546875|2024|   10| 13|  12|1728821618|      562511|2024-10-13T12:13:...|2024-10-13T12:13:...|2024-10-13|\n+--------------+--------+------+-------------+------------------+-----------+----+-----------+------------+------------+----+-----+---+----+----------+------------+--------------------+--------------------+----------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "mouse_movements = df.filter(\"activity_type = 'mouse_movement'\")\n",
    "\n",
    "mouse_movements.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6afa7715-e9b6-40fa-8bb5-b68918426c81",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- activity_type: string (nullable = true)\n |-- app_name: string (nullable = true)\n |-- button: string (nullable = true)\n |-- idle_duration: double (nullable = true)\n |-- timestamp: string (nullable = true)\n |-- window_name: string (nullable = true)\n |-- word: string (nullable = true)\n |-- word_length: long (nullable = true)\n |-- x: double (nullable = true)\n |-- y: double (nullable = true)\n |-- year: integer (nullable = true)\n |-- month: integer (nullable = true)\n |-- day: integer (nullable = true)\n |-- hour: integer (nullable = true)\n |-- seconds: long (nullable = true)\n |-- milliseconds: integer (nullable = true)\n |-- timestamp_test: string (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "mouse_movements.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d6b49da4-2e62-4555-98a0-58895c1f027a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "com.databricks.backend.common.rpc.CommandCancelledException\n",
       "\tat com.databricks.spark.chauffeur.SequenceExecutionState.$anonfun$cancel$5(SequenceExecutionState.scala:136)\n",
       "\tat scala.Option.getOrElse(Option.scala:189)\n",
       "\tat com.databricks.spark.chauffeur.SequenceExecutionState.$anonfun$cancel$3(SequenceExecutionState.scala:136)\n",
       "\tat com.databricks.spark.chauffeur.SequenceExecutionState.$anonfun$cancel$3$adapted(SequenceExecutionState.scala:133)\n",
       "\tat scala.collection.immutable.Range.foreach(Range.scala:158)\n",
       "\tat com.databricks.spark.chauffeur.SequenceExecutionState.cancel(SequenceExecutionState.scala:133)\n",
       "\tat com.databricks.spark.chauffeur.ExecContextState.cancelRunningSequence(ExecContextState.scala:728)\n",
       "\tat com.databricks.spark.chauffeur.ExecContextState.$anonfun$cancel$1(ExecContextState.scala:446)\n",
       "\tat scala.Option.getOrElse(Option.scala:189)\n",
       "\tat com.databricks.spark.chauffeur.ExecContextState.cancel(ExecContextState.scala:446)\n",
       "\tat com.databricks.spark.chauffeur.ExecutionContextManagerV1.cancelExecution(ExecutionContextManagerV1.scala:460)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.$anonfun$process$1(ChauffeurState.scala:577)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:527)\n",
       "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:631)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:651)\n",
       "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)\n",
       "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:276)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:272)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.withAttributionContext(ChauffeurState.scala:57)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:95)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:76)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.withAttributionTags(ChauffeurState.scala:57)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:626)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:536)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.recordOperationWithResultTags(ChauffeurState.scala:57)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:528)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:496)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.recordOperation(ChauffeurState.scala:57)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.process(ChauffeurState.scala:559)\n",
       "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.handleDriverRequest$1(Chauffeur.scala:820)\n",
       "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.$anonfun$applyOrElse$5(Chauffeur.scala:846)\n",
       "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:631)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:651)\n",
       "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)\n",
       "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:276)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:272)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)\n",
       "\tat com.databricks.rpc.ServerBackend.withAttributionContext(ServerBackend.scala:22)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:95)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:76)\n",
       "\tat com.databricks.rpc.ServerBackend.withAttributionTags(ServerBackend.scala:22)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:626)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:536)\n",
       "\tat com.databricks.rpc.ServerBackend.recordOperationWithResultTags(ServerBackend.scala:22)\n",
       "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.handleDriverRequestWithUsageLogging$1(Chauffeur.scala:845)\n",
       "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.applyOrElse(Chauffeur.scala:900)\n",
       "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.applyOrElse(Chauffeur.scala:693)\n",
       "\tat com.databricks.rpc.ServerBackend.$anonfun$internalReceive0$2(ServerBackend.scala:174)\n",
       "\tat com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:200)\n",
       "\tat com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:200)\n",
       "\tat com.databricks.rpc.ServerBackend.internalReceive0(ServerBackend.scala:171)\n",
       "\tat com.databricks.rpc.ServerBackend.$anonfun$internalReceive$1(ServerBackend.scala:147)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:527)\n",
       "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:631)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:651)\n",
       "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)\n",
       "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:276)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:272)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)\n",
       "\tat com.databricks.rpc.ServerBackend.withAttributionContext(ServerBackend.scala:22)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:95)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:76)\n",
       "\tat com.databricks.rpc.ServerBackend.withAttributionTags(ServerBackend.scala:22)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:626)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:536)\n",
       "\tat com.databricks.rpc.ServerBackend.recordOperationWithResultTags(ServerBackend.scala:22)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:528)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:496)\n",
       "\tat com.databricks.rpc.ServerBackend.recordOperation(ServerBackend.scala:22)\n",
       "\tat com.databricks.rpc.ServerBackend.internalReceive(ServerBackend.scala:146)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.handleRPC(JettyServer.scala:1021)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.handleRequestAndRespond(JettyServer.scala:942)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleHttp$6(JettyServer.scala:546)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleHttp$6$adapted(JettyServer.scala:515)\n",
       "\tat com.databricks.logging.activity.ActivityContextFactory$.$anonfun$withActivityInternal$6(ActivityContextFactory.scala:545)\n",
       "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)\n",
       "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:276)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:272)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)\n",
       "\tat com.databricks.logging.activity.ActivityContextFactory$.withAttributionContext(ActivityContextFactory.scala:48)\n",
       "\tat com.databricks.logging.activity.ActivityContextFactory$.$anonfun$withActivityInternal$3(ActivityContextFactory.scala:545)\n",
       "\tat com.databricks.context.integrity.IntegrityCheckContext$ThreadLocalStorage$.withValue(IntegrityCheckContext.scala:73)\n",
       "\tat com.databricks.logging.activity.ActivityContextFactory$.withActivityInternal(ActivityContextFactory.scala:523)\n",
       "\tat com.databricks.logging.activity.ActivityContextFactory$.withServiceRequestActivity(ActivityContextFactory.scala:175)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.handleHttp(JettyServer.scala:515)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.doPost(JettyServer.scala:405)\n",
       "\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:665)\n",
       "\tat com.databricks.rpc.HttpServletWithPatch.service(HttpServletWithPatch.scala:33)\n",
       "\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:750)\n",
       "\tat org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)\n",
       "\tat org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:554)\n",
       "\tat org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:190)\n",
       "\tat org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:505)\n",
       "\tat org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)\n",
       "\tat org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)\n",
       "\tat org.eclipse.jetty.server.Server.handle(Server.java:516)\n",
       "\tat org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:487)\n",
       "\tat org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:732)\n",
       "\tat org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:479)\n",
       "\tat org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)\n",
       "\tat org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)\n",
       "\tat org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)\n",
       "\tat org.eclipse.jetty.io.ssl.SslConnection$DecryptedEndPoint.onFillable(SslConnection.java:555)\n",
       "\tat org.eclipse.jetty.io.ssl.SslConnection.onFillable(SslConnection.java:410)\n",
       "\tat org.eclipse.jetty.io.ssl.SslConnection$2.succeeded(SslConnection.java:164)\n",
       "\tat org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)\n",
       "\tat org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)\n",
       "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)\n",
       "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)\n",
       "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)\n",
       "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)\n",
       "\tat org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:409)\n",
       "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.$anonfun$run$2(InstrumentedQueuedThreadPool.scala:105)\n",
       "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
       "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)\n",
       "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:276)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:272)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)\n",
       "\tat com.databricks.rpc.InstrumentedQueuedThreadPool.withAttributionContext(InstrumentedQueuedThreadPool.scala:45)\n",
       "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.$anonfun$run$1(InstrumentedQueuedThreadPool.scala:105)\n",
       "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
       "\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads(QueuedThreadPoolInstrumenter.scala:110)\n",
       "\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads$(QueuedThreadPoolInstrumenter.scala:107)\n",
       "\tat com.databricks.rpc.InstrumentedQueuedThreadPool.trackActiveThreads(InstrumentedQueuedThreadPool.scala:45)\n",
       "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.run(InstrumentedQueuedThreadPool.scala:87)\n",
       "\tat org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)\n",
       "\tat org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)\n",
       "\tat java.lang.Thread.run(Thread.java:750)"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "datasetInfos": [],
       "jupyterProps": null,
       "metadata": {
        "errorSummary": "Cancelled"
       },
       "removedWidgets": [],
       "sqlProps": null,
       "stackFrames": [
        "com.databricks.backend.common.rpc.CommandCancelledException",
        "\tat com.databricks.spark.chauffeur.SequenceExecutionState.$anonfun$cancel$5(SequenceExecutionState.scala:136)",
        "\tat scala.Option.getOrElse(Option.scala:189)",
        "\tat com.databricks.spark.chauffeur.SequenceExecutionState.$anonfun$cancel$3(SequenceExecutionState.scala:136)",
        "\tat com.databricks.spark.chauffeur.SequenceExecutionState.$anonfun$cancel$3$adapted(SequenceExecutionState.scala:133)",
        "\tat scala.collection.immutable.Range.foreach(Range.scala:158)",
        "\tat com.databricks.spark.chauffeur.SequenceExecutionState.cancel(SequenceExecutionState.scala:133)",
        "\tat com.databricks.spark.chauffeur.ExecContextState.cancelRunningSequence(ExecContextState.scala:728)",
        "\tat com.databricks.spark.chauffeur.ExecContextState.$anonfun$cancel$1(ExecContextState.scala:446)",
        "\tat scala.Option.getOrElse(Option.scala:189)",
        "\tat com.databricks.spark.chauffeur.ExecContextState.cancel(ExecContextState.scala:446)",
        "\tat com.databricks.spark.chauffeur.ExecutionContextManagerV1.cancelExecution(ExecutionContextManagerV1.scala:460)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.$anonfun$process$1(ChauffeurState.scala:577)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:527)",
        "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:631)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:651)",
        "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)",
        "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:276)",
        "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)",
        "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:272)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.withAttributionContext(ChauffeurState.scala:57)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:95)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:76)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.withAttributionTags(ChauffeurState.scala:57)",
        "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:626)",
        "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:536)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.recordOperationWithResultTags(ChauffeurState.scala:57)",
        "\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:528)",
        "\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:496)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.recordOperation(ChauffeurState.scala:57)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.process(ChauffeurState.scala:559)",
        "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.handleDriverRequest$1(Chauffeur.scala:820)",
        "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.$anonfun$applyOrElse$5(Chauffeur.scala:846)",
        "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:631)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:651)",
        "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)",
        "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:276)",
        "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)",
        "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:272)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)",
        "\tat com.databricks.rpc.ServerBackend.withAttributionContext(ServerBackend.scala:22)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:95)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:76)",
        "\tat com.databricks.rpc.ServerBackend.withAttributionTags(ServerBackend.scala:22)",
        "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:626)",
        "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:536)",
        "\tat com.databricks.rpc.ServerBackend.recordOperationWithResultTags(ServerBackend.scala:22)",
        "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.handleDriverRequestWithUsageLogging$1(Chauffeur.scala:845)",
        "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.applyOrElse(Chauffeur.scala:900)",
        "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.applyOrElse(Chauffeur.scala:693)",
        "\tat com.databricks.rpc.ServerBackend.$anonfun$internalReceive0$2(ServerBackend.scala:174)",
        "\tat com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:200)",
        "\tat com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:200)",
        "\tat com.databricks.rpc.ServerBackend.internalReceive0(ServerBackend.scala:171)",
        "\tat com.databricks.rpc.ServerBackend.$anonfun$internalReceive$1(ServerBackend.scala:147)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:527)",
        "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:631)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:651)",
        "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)",
        "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:276)",
        "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)",
        "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:272)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)",
        "\tat com.databricks.rpc.ServerBackend.withAttributionContext(ServerBackend.scala:22)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:95)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:76)",
        "\tat com.databricks.rpc.ServerBackend.withAttributionTags(ServerBackend.scala:22)",
        "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:626)",
        "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:536)",
        "\tat com.databricks.rpc.ServerBackend.recordOperationWithResultTags(ServerBackend.scala:22)",
        "\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:528)",
        "\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:496)",
        "\tat com.databricks.rpc.ServerBackend.recordOperation(ServerBackend.scala:22)",
        "\tat com.databricks.rpc.ServerBackend.internalReceive(ServerBackend.scala:146)",
        "\tat com.databricks.rpc.JettyServer$RequestManager.handleRPC(JettyServer.scala:1021)",
        "\tat com.databricks.rpc.JettyServer$RequestManager.handleRequestAndRespond(JettyServer.scala:942)",
        "\tat com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleHttp$6(JettyServer.scala:546)",
        "\tat com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleHttp$6$adapted(JettyServer.scala:515)",
        "\tat com.databricks.logging.activity.ActivityContextFactory$.$anonfun$withActivityInternal$6(ActivityContextFactory.scala:545)",
        "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)",
        "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:276)",
        "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)",
        "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:272)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)",
        "\tat com.databricks.logging.activity.ActivityContextFactory$.withAttributionContext(ActivityContextFactory.scala:48)",
        "\tat com.databricks.logging.activity.ActivityContextFactory$.$anonfun$withActivityInternal$3(ActivityContextFactory.scala:545)",
        "\tat com.databricks.context.integrity.IntegrityCheckContext$ThreadLocalStorage$.withValue(IntegrityCheckContext.scala:73)",
        "\tat com.databricks.logging.activity.ActivityContextFactory$.withActivityInternal(ActivityContextFactory.scala:523)",
        "\tat com.databricks.logging.activity.ActivityContextFactory$.withServiceRequestActivity(ActivityContextFactory.scala:175)",
        "\tat com.databricks.rpc.JettyServer$RequestManager.handleHttp(JettyServer.scala:515)",
        "\tat com.databricks.rpc.JettyServer$RequestManager.doPost(JettyServer.scala:405)",
        "\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:665)",
        "\tat com.databricks.rpc.HttpServletWithPatch.service(HttpServletWithPatch.scala:33)",
        "\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:750)",
        "\tat org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)",
        "\tat org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:554)",
        "\tat org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:190)",
        "\tat org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:505)",
        "\tat org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)",
        "\tat org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)",
        "\tat org.eclipse.jetty.server.Server.handle(Server.java:516)",
        "\tat org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:487)",
        "\tat org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:732)",
        "\tat org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:479)",
        "\tat org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)",
        "\tat org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)",
        "\tat org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)",
        "\tat org.eclipse.jetty.io.ssl.SslConnection$DecryptedEndPoint.onFillable(SslConnection.java:555)",
        "\tat org.eclipse.jetty.io.ssl.SslConnection.onFillable(SslConnection.java:410)",
        "\tat org.eclipse.jetty.io.ssl.SslConnection$2.succeeded(SslConnection.java:164)",
        "\tat org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)",
        "\tat org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)",
        "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)",
        "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)",
        "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)",
        "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)",
        "\tat org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:409)",
        "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.$anonfun$run$2(InstrumentedQueuedThreadPool.scala:105)",
        "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)",
        "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:48)",
        "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:276)",
        "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)",
        "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:272)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:46)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:43)",
        "\tat com.databricks.rpc.InstrumentedQueuedThreadPool.withAttributionContext(InstrumentedQueuedThreadPool.scala:45)",
        "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.$anonfun$run$1(InstrumentedQueuedThreadPool.scala:105)",
        "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)",
        "\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads(QueuedThreadPoolInstrumenter.scala:110)",
        "\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads$(QueuedThreadPoolInstrumenter.scala:107)",
        "\tat com.databricks.rpc.InstrumentedQueuedThreadPool.trackActiveThreads(InstrumentedQueuedThreadPool.scala:45)",
        "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.run(InstrumentedQueuedThreadPool.scala:87)",
        "\tat org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)",
        "\tat org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)",
        "\tat java.lang.Thread.run(Thread.java:750)"
       ],
       "type": "baseError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "mouse_clicks = df.filter(\"activity_type = 'mouse_click'\")\n",
    "\n",
    "mouse_clicks.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4fd3de87-b511-4d50-92bf-fe607b773ff1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------+------+-------------+------------------+-----------+----+-----------+------------+------------+----+-----+---+----+----------+------------+--------------------+\n| activity_type|app_name|button|idle_duration|         timestamp|window_name|word|word_length|           x|           y|year|month|day|hour|   seconds|milliseconds|      timestamp_test|\n+--------------+--------+------+-------------+------------------+-----------+----+-----------+------------+------------+----+-----+---+----+----------+------------+--------------------+\n|mouse_movement|    NULL|  NULL|         NULL|1728821618.1731782|       NULL|NULL|       NULL| 453.3203125|783.41015625|2024|   10| 13|  12|1728821618|         173|2024-10-13T12:13:...|\n|mouse_movement|    NULL|  NULL|         NULL| 1728821618.326953|       NULL|NULL|       NULL| 453.3203125| 785.7890625|2024|   10| 13|  12|1728821618|         326|2024-10-13T12:13:...|\n|mouse_movement|    NULL|  NULL|         NULL| 1728821618.352664|       NULL|NULL|       NULL| 453.3203125|787.15234375|2024|   10| 13|  12|1728821618|         352|2024-10-13T12:13:...|\n|mouse_movement|    NULL|  NULL|         NULL| 1728821618.173179|       NULL|NULL|       NULL| 453.3203125|783.41015625|2024|   10| 13|  12|1728821618|         173|2024-10-13T12:13:...|\n|mouse_movement|    NULL|  NULL|         NULL| 1728821618.378138|       NULL|NULL|       NULL| 453.3203125| 785.7890625|2024|   10| 13|  12|1728821618|         378|2024-10-13T12:13:...|\n|mouse_movement|    NULL|  NULL|         NULL| 1728821618.377547|       NULL|NULL|       NULL| 453.3203125|787.72265625|2024|   10| 13|  12|1728821618|         377|2024-10-13T12:13:...|\n|mouse_movement|    NULL|  NULL|         NULL|   1728821618.4006|       NULL|NULL|       NULL| 453.3203125|787.98046875|2024|   10| 13|  12|1728821618|         400|2024-10-13T12:13:...|\n|mouse_movement|    NULL|  NULL|         NULL| 1728821618.399573|       NULL|NULL|       NULL| 453.3203125|787.15234375|2024|   10| 13|  12|1728821618|         399|2024-10-13T12:13:...|\n|mouse_movement|    NULL|  NULL|         NULL|1728821618.4219332|       NULL|NULL|       NULL| 453.3203125|788.23828125|2024|   10| 13|  12|1728821618|         421|2024-10-13T12:13:...|\n|mouse_movement|    NULL|  NULL|         NULL| 1728821618.425057|       NULL|NULL|       NULL| 453.3203125|787.72265625|2024|   10| 13|  12|1728821618|         425|2024-10-13T12:13:...|\n|mouse_movement|    NULL|  NULL|         NULL| 1728821618.445018|       NULL|NULL|       NULL|453.08203125|788.23828125|2024|   10| 13|  12|1728821618|         445|2024-10-13T12:13:...|\n|mouse_movement|    NULL|  NULL|         NULL| 1728821618.450161|       NULL|NULL|       NULL| 453.3203125|787.98046875|2024|   10| 13|  12|1728821618|         450|2024-10-13T12:13:...|\n|mouse_movement|    NULL|  NULL|         NULL| 1728821618.466635|       NULL|NULL|       NULL| 452.8203125|788.23828125|2024|   10| 13|  12|1728821618|         466|2024-10-13T12:13:...|\n|mouse_movement|    NULL|  NULL|         NULL| 1728821618.475542|       NULL|NULL|       NULL| 453.3203125|788.23828125|2024|   10| 13|  12|1728821618|         475|2024-10-13T12:13:...|\n|mouse_movement|    NULL|  NULL|         NULL| 1728821618.492105|       NULL|NULL|       NULL| 452.8203125|785.85546875|2024|   10| 13|  12|1728821618|         492|2024-10-13T12:13:...|\n|mouse_movement|    NULL|  NULL|         NULL| 1728821618.500888|       NULL|NULL|       NULL|453.08203125|788.23828125|2024|   10| 13|  12|1728821618|         500|2024-10-13T12:13:...|\n|mouse_movement|    NULL|  NULL|         NULL| 1728821618.516033|       NULL|NULL|       NULL| 452.8203125|779.08203125|2024|   10| 13|  12|1728821618|         516|2024-10-13T12:13:...|\n|mouse_movement|    NULL|  NULL|         NULL| 1728821618.534318|       NULL|NULL|       NULL| 452.8203125|788.23828125|2024|   10| 13|  12|1728821618|         534|2024-10-13T12:13:...|\n|mouse_movement|    NULL|  NULL|         NULL|  1728821618.53982|       NULL|NULL|       NULL| 452.8203125| 768.2578125|2024|   10| 13|  12|1728821618|         539|2024-10-13T12:13:...|\n|mouse_movement|    NULL|  NULL|         NULL|1728821618.5625112|       NULL|NULL|       NULL| 452.8203125|785.85546875|2024|   10| 13|  12|1728821618|         562|2024-10-13T12:13:...|\n+--------------+--------+------+-------------+------------------+-----------+----+-----------+------------+------------+----+-----+---+----+----------+------------+--------------------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "dftime.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "41c1b12d-e089-4464-ad3b-c3b2eca3af3f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Convert the Unix Timestamps for the mouse movements into Date Time with milliseconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1db5c2e8-6204-4b00-ab24-a306caaabc87",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = df.withColumn(\"seconds\", floor(col(\"timestamp\"))) \\\n",
    "       .withColumn(\"milliseconds\", ((col(\"timestamp\") - col(\"seconds\")) * 1000000).cast(\"int\"))\n",
    "\n",
    "# Convert integer seconds to formatted datetime, add milliseconds part\n",
    "df = df.withColumn(\"timestamp_mouse\", \n",
    "                   F.when(F.col(\"activity_type\").isin(\"mouse_movement\", \"mouse_click\"),\n",
    "                          expr(\"from_unixtime(seconds, 'yyyy-MM-dd') || 'T' || from_unixtime(seconds, 'HH:mm:ss') || '.' || lpad(milliseconds, 6, '0')\")\n",
    "                         ).otherwise(F.col(\"timestamp\"))\n",
    "                  )\n",
    "\n",
    "df = df.withColumn(\"date\", F.date_format(\"timestamp_mouse\", \"yyyy-MM-dd\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bca8ea25-547d-461f-9026-b72604c69127",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-10-13T12:13:38.326952\nBreak\n2024-10-26T17:28:58.136904\n"
     ]
    }
   ],
   "source": [
    "print(df.limit(2).select(\"timestamp_mouse\").collect()[1][\"timestamp_mouse\"])\n",
    "print(\"Break\")\n",
    "print(app_change.limit(2).select('timestamp').collect()[1]['timestamp'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "133b8e88-3ce6-49d5-9867-954067209855",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Calculate the Distance and Angle of the mouse movements "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "04118488-3fd3-4cb9-bf1c-05d052ac74c2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Angle threshold for detecting direction changes\n",
    "ANGLE_CHANGE_THRESHOLD = 70  # Degrees\n",
    "MIN_DISTANCE_THRESHOLD = 50  # Minimum distance to consider as movement\n",
    "\n",
    "# Calculate distance traveled for each row\n",
    "def calculate_distance(x1, y1, x2, y2):\n",
    "    if x1 is None or y1 is None or x2 is None or y2 is None:\n",
    "        return 0.0\n",
    "    return math.sqrt((x2 - x1)**2 + (y2 - y1)**2)\n",
    "\n",
    "def calculate_angle(x1, y1, x2, y2, x3, y3):\n",
    "    if None in (x1, y1, x2, y2, x3, y3):\n",
    "        return 0.0\n",
    "    # Vectors (x1, y1) -> (x2, y2) and (x2, y2) -> (x3, y3)\n",
    "    v1x, v1y = x2 - x1, y2 - y1\n",
    "    v2x, v2y = x3 - x2, y3 - y2\n",
    "    # Calculate magnitudes\n",
    "    mag1 = math.sqrt(v1x**2 + v1y**2)\n",
    "    mag2 = math.sqrt(v2x**2 + v2y**2)\n",
    "    if mag1 < MIN_DISTANCE_THRESHOLD or mag2 < MIN_DISTANCE_THRESHOLD:\n",
    "        return 0.0  # Ignore small movements\n",
    "    # Calculate the cosine of the angle\n",
    "    dot_product = v1x * v2x + v1y * v2y\n",
    "    cos_theta = dot_product / (mag1 * mag2)\n",
    "    # Clamp cos_theta to avoid domain errors\n",
    "    cos_theta = max(-1, min(1, cos_theta))\n",
    "    # Convert to angle in degrees\n",
    "    angle = math.degrees(math.acos(cos_theta))\n",
    "    return angle\n",
    "\n",
    "# UDF to calculate distance\n",
    "distance_udf = F.udf(calculate_distance, DoubleType())\n",
    "# UDF for angle calculation\n",
    "angle_udf = F.udf(calculate_angle, DoubleType())\n",
    "\n",
    "# Lag to get previous coordinates\n",
    "window_spec = Window.partitionBy(\"year\", \"month\", \"day\", \"hour\", \"minute\").orderBy(\"timestamp\")\n",
    "df = df.withColumn(\"x_prev\", F.lag(\"x\", 1).over(window_spec))\n",
    "df = df.withColumn(\"y_prev\", F.lag(\"y\", 1).over(window_spec))\n",
    "df = df.withColumn(\"x_next\", F.lead(\"x\", 1).over(window_spec))\n",
    "df = df.withColumn(\"y_next\", F.lead(\"y\", 1).over(window_spec))\n",
    "\n",
    "df = df.withColumn(\"distance\", distance_udf(\"x\", \"y\", \"x_prev\", \"y_prev\"))\n",
    "df = df.withColumn(\"angle\", angle_udf(\"x_prev\", \"y_prev\", \"x\", \"y\", \"x_next\", \"y_next\"))\n",
    "\n",
    "# Calculate direction changes by comparing consecutive angles\n",
    "df = df.withColumn(\"angle_prev\", F.lag(\"angle\").over(window_spec))\n",
    "\n",
    "# Detect direction change based on angle exceeding threshold\n",
    "df = df.withColumn(\"direction_change\", F.when(F.col(\"angle\") > ANGLE_CHANGE_THRESHOLD, 1).otherwise(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d48569d7-6a28-439b-8c11-317ff059308c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Aggregation to calculate total distance and direction changes by minute\n",
    "result = df.groupBy(\"year\", \"month\", \"day\", \"hour\", \"minute\").agg(\n",
    "    F.sum(\"distance\").alias(\"total_distance\"),\n",
    "    F.sum(\"direction_change\").alias(\"direction_changes\"),\n",
    "    F.sum(F.when(F.col(\"activity_type\") == \"word_completed\",1).otherwise(0)).alias(\"total_words\"),\n",
    "    F.avg(F.when(F.col(\"activity_type\") == \"word_completed\",F.col(\"word_length\")).otherwise(None)).alias(\"avg_word_length\"),\n",
    "    F.sum(F.when(F.col(\"activity_type\") == \"mouse_click\", 1).otherwise(0)).alias(\"clicks_count\")\n",
    ")\n",
    "\n",
    "result = result.withColumn(\n",
    "                \"date\",\n",
    "                F.to_date(F.concat(F.col('year'), F.lit('-'), F.col('month'), F.lit('-'), F.col('day')), \"yyyy-MM-dd\")\n",
    ")\n",
    "\n",
    "result.show()\n",
    "\n",
    "print(f'Number of rows in groupby = {result.count()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "54a62e74-6e73-471d-9d42-be31c0a966b1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "app_change = app_change.withColumn(\"timestamp_end\", F.lead(\"timestamp\").over(Window.orderBy('timestamp')))\n",
    "\n",
    "mouse_movements = mouse_movements.alias(\"mouse_movements\")\n",
    "app_change = app_change.alias(\"app_change\")\n",
    "\n",
    "app_change_mouse_movements = app_change.join(mouse_movements,\n",
    "                                             (F.col(\"mouse_movements.timestamp_mouse\") >= F.col(\"app_change.timestamp\")) &\n",
    "                                             (F.col(\"mouse_movements.timestamp_mouse\") < F.col(\"app_change.timestamp_end\")),\n",
    "                                             how=\"left\" )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "efb58504-6bf4-4481-b758-6d4b848f41ff",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "app_change_mouse_movements = app_change_mouse_movements.withColumn(\"timestamp_start_unix\", F.unix_timestamp(\"app_change.timestamp\", \"yyyy-MM-dd'T'HH:mm:ss.SSSSSS\"))\n",
    "app_change_mouse_movements = app_change_mouse_movements.withColumn(\"timestamp_end_unix\", F.unix_timestamp(\"app_change.timestamp_end\", \"yyyy-MM-dd'T'HH:mm:ss.SSSSSS\"))\n",
    "\n",
    "app_change_mouse_movements = app_change_mouse_movements.withColumn(\"time_diff_seconds\", F.col('timestamp_end_unix') - F.col('timestamp_start_unix'))\n",
    "\n",
    "# If you want the difference in a more readable format, like hours, minutes, etc.\n",
    "app_change_mouse_movements = app_change_mouse_movements.withColumn(\"time_diff_minutes\", F.col(\"time_diff_seconds\") / 60)  # For minutes\n",
    "app_change_mouse_movements = app_change_mouse_movements.withColumn(\"time_diff_hours\", F.col(\"time_diff_seconds\") / 3600)\n",
    "\n",
    "app_change_mouse_movements = app_change_mouse_movements.withColumn(\"timestamp_range\", F.concat(F.col(\"app_change.timestamp\"), F.lit(\" to \"), F.col(\"app_change.timestamp_end\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2ad3e584-23f0-429f-93fd-f4567d9a0f33",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------------------------------------------------------+-----------------+-----------------+--------------------------+\n|app_name           |timestamp_range                                         |time_diff_seconds|time_diff_minutes|timestamp_mouse           |\n+-------------------+--------------------------------------------------------+-----------------+-----------------+--------------------------+\n|AppleScript Utility|2024-10-09T16:12:04.367325 to 2024-10-09T16:15:08.513721|184              |3.066666666666667|2024-10-09T16:14:14.262912|\n|AppleScript Utility|2024-10-09T16:12:04.367325 to 2024-10-09T16:15:08.513721|184              |3.066666666666667|2024-10-09T16:14:14.479892|\n|AppleScript Utility|2024-10-09T16:12:04.367325 to 2024-10-09T16:15:08.513721|184              |3.066666666666667|2024-10-09T16:14:14.508553|\n|AppleScript Utility|2024-10-09T16:12:04.367325 to 2024-10-09T16:15:08.513721|184              |3.066666666666667|2024-10-09T16:14:14.537649|\n|AppleScript Utility|2024-10-09T16:12:04.367325 to 2024-10-09T16:15:08.513721|184              |3.066666666666667|2024-10-09T16:14:14.566657|\n|AppleScript Utility|2024-10-09T16:12:04.367325 to 2024-10-09T16:15:08.513721|184              |3.066666666666667|2024-10-09T16:14:14.595087|\n|AppleScript Utility|2024-10-09T16:12:04.367325 to 2024-10-09T16:15:08.513721|184              |3.066666666666667|2024-10-09T16:14:14.623180|\n|AppleScript Utility|2024-10-09T16:12:04.367325 to 2024-10-09T16:15:08.513721|184              |3.066666666666667|2024-10-09T16:14:14.652048|\n|AppleScript Utility|2024-10-09T16:12:04.367325 to 2024-10-09T16:15:08.513721|184              |3.066666666666667|2024-10-09T16:14:14.684176|\n|AppleScript Utility|2024-10-09T16:12:04.367325 to 2024-10-09T16:15:08.513721|184              |3.066666666666667|2024-10-09T16:14:14.716011|\n|AppleScript Utility|2024-10-09T16:12:04.367325 to 2024-10-09T16:15:08.513721|184              |3.066666666666667|2024-10-09T16:14:14.742541|\n|AppleScript Utility|2024-10-09T16:12:04.367325 to 2024-10-09T16:15:08.513721|184              |3.066666666666667|2024-10-09T16:14:14.772116|\n|AppleScript Utility|2024-10-09T16:12:04.367325 to 2024-10-09T16:15:08.513721|184              |3.066666666666667|2024-10-09T16:14:14.801700|\n|AppleScript Utility|2024-10-09T16:12:04.367325 to 2024-10-09T16:15:08.513721|184              |3.066666666666667|2024-10-09T16:14:14.829654|\n|AppleScript Utility|2024-10-09T16:12:04.367325 to 2024-10-09T16:15:08.513721|184              |3.066666666666667|2024-10-09T16:14:14.855246|\n|AppleScript Utility|2024-10-09T16:12:04.367325 to 2024-10-09T16:15:08.513721|184              |3.066666666666667|2024-10-09T16:14:14.884121|\n|AppleScript Utility|2024-10-09T16:12:04.367325 to 2024-10-09T16:15:08.513721|184              |3.066666666666667|2024-10-09T16:14:14.911919|\n|AppleScript Utility|2024-10-09T16:12:04.367325 to 2024-10-09T16:15:08.513721|184              |3.066666666666667|2024-10-09T16:14:14.937824|\n|AppleScript Utility|2024-10-09T16:12:04.367325 to 2024-10-09T16:15:08.513721|184              |3.066666666666667|2024-10-09T16:14:14.964474|\n|AppleScript Utility|2024-10-09T16:12:04.367325 to 2024-10-09T16:15:08.513721|184              |3.066666666666667|2024-10-09T16:14:14.992377|\n+-------------------+--------------------------------------------------------+-----------------+-----------------+--------------------------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "app_change_mouse_movements.select(\"app_change.app_name\", \"timestamp_range\", \"time_diff_seconds\", \"time_diff_minutes\",\"mouse_movements.timestamp_mouse\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e7813a6a-a1a2-4d6e-92e6-269c0a190eb5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7a8b2605-b1d9-4d5d-ad23-682c4b8e670b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "app_change_mouse_agg = app_change_mouse_movements.groupBy().agg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ab35a289-8968-45d6-bbd5-a58df9fbb657",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(result.count())\n",
    "\n",
    "results_sample = result.sample(fraction=0.5).orderBy(rand()).limit(50)\n",
    "\n",
    "display(results_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2f42d7b6-e508-44ba-b458-2572ee57cce3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "result.write.format(\"delta\").option(\"overwriteSchema\", \"true\").mode(\"overwrite\").saveAsTable(\"mouse_activity_summary\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3d69da2b-2e11-491b-94ee-3de80a0b466e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mAnalysisException\u001B[0m                         Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-1244502079990473>, line 11\u001B[0m\n",
       "\u001B[1;32m      8\u001B[0m mouse_movements_alias \u001B[38;5;241m=\u001B[39m mouse_movements\u001B[38;5;241m.\u001B[39malias(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmouse_movements\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
       "\u001B[1;32m     10\u001B[0m \u001B[38;5;66;03m# Perform the join with qualified column names\u001B[39;00m\n",
       "\u001B[0;32m---> 11\u001B[0m app_change_mouse_movements \u001B[38;5;241m=\u001B[39m app_change_alias\u001B[38;5;241m.\u001B[39mjoin(\n",
       "\u001B[1;32m     12\u001B[0m     mouse_movements_alias,\n",
       "\u001B[1;32m     13\u001B[0m     (mouse_movements_alias\u001B[38;5;241m.\u001B[39mdatetime_msecs \u001B[38;5;241m>\u001B[39m\u001B[38;5;241m=\u001B[39m app_change_alias\u001B[38;5;241m.\u001B[39mdatetime_msecs) \u001B[38;5;241m&\u001B[39m\n",
       "\u001B[1;32m     14\u001B[0m     (mouse_movements_alias\u001B[38;5;241m.\u001B[39mdatetime_msecs \u001B[38;5;241m<\u001B[39m app_change_alias\u001B[38;5;241m.\u001B[39mend_datetime_msecs),\n",
       "\u001B[1;32m     15\u001B[0m     how\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mleft\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
       "\u001B[1;32m     16\u001B[0m )\n",
       "\u001B[1;32m     18\u001B[0m display(app_change_mouse_movements)\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/pyspark/instrumentation_utils.py:47\u001B[0m, in \u001B[0;36m_wrap_function.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n",
       "\u001B[1;32m     45\u001B[0m start \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mperf_counter()\n",
       "\u001B[1;32m     46\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n",
       "\u001B[0;32m---> 47\u001B[0m     res \u001B[38;5;241m=\u001B[39m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
       "\u001B[1;32m     48\u001B[0m     logger\u001B[38;5;241m.\u001B[39mlog_success(\n",
       "\u001B[1;32m     49\u001B[0m         module_name, class_name, function_name, time\u001B[38;5;241m.\u001B[39mperf_counter() \u001B[38;5;241m-\u001B[39m start, signature\n",
       "\u001B[1;32m     50\u001B[0m     )\n",
       "\u001B[1;32m     51\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m res\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/pyspark/sql/dataframe.py:2979\u001B[0m, in \u001B[0;36mDataFrame.join\u001B[0;34m(self, other, on, how)\u001B[0m\n",
       "\u001B[1;32m   2977\u001B[0m         on \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jseq([])\n",
       "\u001B[1;32m   2978\u001B[0m     \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(how, \u001B[38;5;28mstr\u001B[39m), \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhow should be a string\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
       "\u001B[0;32m-> 2979\u001B[0m     jdf \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jdf\u001B[38;5;241m.\u001B[39mjoin(other\u001B[38;5;241m.\u001B[39m_jdf, on, how)\n",
       "\u001B[1;32m   2980\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m DataFrame(jdf, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msparkSession)\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py:1355\u001B[0m, in \u001B[0;36mJavaMember.__call__\u001B[0;34m(self, *args)\u001B[0m\n",
       "\u001B[1;32m   1349\u001B[0m command \u001B[38;5;241m=\u001B[39m proto\u001B[38;5;241m.\u001B[39mCALL_COMMAND_NAME \u001B[38;5;241m+\u001B[39m\\\n",
       "\u001B[1;32m   1350\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcommand_header \u001B[38;5;241m+\u001B[39m\\\n",
       "\u001B[1;32m   1351\u001B[0m     args_command \u001B[38;5;241m+\u001B[39m\\\n",
       "\u001B[1;32m   1352\u001B[0m     proto\u001B[38;5;241m.\u001B[39mEND_COMMAND_PART\n",
       "\u001B[1;32m   1354\u001B[0m answer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgateway_client\u001B[38;5;241m.\u001B[39msend_command(command)\n",
       "\u001B[0;32m-> 1355\u001B[0m return_value \u001B[38;5;241m=\u001B[39m get_return_value(\n",
       "\u001B[1;32m   1356\u001B[0m     answer, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgateway_client, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtarget_id, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mname)\n",
       "\u001B[1;32m   1358\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m temp_arg \u001B[38;5;129;01min\u001B[39;00m temp_args:\n",
       "\u001B[1;32m   1359\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(temp_arg, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_detach\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/pyspark/errors/exceptions/captured.py:261\u001B[0m, in \u001B[0;36mcapture_sql_exception.<locals>.deco\u001B[0;34m(*a, **kw)\u001B[0m\n",
       "\u001B[1;32m    257\u001B[0m converted \u001B[38;5;241m=\u001B[39m convert_exception(e\u001B[38;5;241m.\u001B[39mjava_exception)\n",
       "\u001B[1;32m    258\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(converted, UnknownException):\n",
       "\u001B[1;32m    259\u001B[0m     \u001B[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001B[39;00m\n",
       "\u001B[1;32m    260\u001B[0m     \u001B[38;5;66;03m# JVM exception message.\u001B[39;00m\n",
       "\u001B[0;32m--> 261\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m converted \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
       "\u001B[1;32m    262\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
       "\u001B[1;32m    263\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m\n",
       "\n",
       "\u001B[0;31mAnalysisException\u001B[0m: Column datetime_msecs#1419, datetime_msecs#1419 are ambiguous. It's probably because you joined several Datasets together, and some of these Datasets are the same. This column points to one of the Datasets but Spark is unable to figure out which one. Please alias the Datasets with different names via `Dataset.as` before joining them, and specify the column using qualified name, e.g. `df.as(\"a\").join(df.as(\"b\"), $\"a.id\" > $\"b.id\")`. You can also set spark.sql.analyzer.failAmbiguousSelfJoin to false to disable this check."
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "datasetInfos": [],
       "jupyterProps": {
        "ename": "AnalysisException",
        "evalue": "Column datetime_msecs#1419, datetime_msecs#1419 are ambiguous. It's probably because you joined several Datasets together, and some of these Datasets are the same. This column points to one of the Datasets but Spark is unable to figure out which one. Please alias the Datasets with different names via `Dataset.as` before joining them, and specify the column using qualified name, e.g. `df.as(\"a\").join(df.as(\"b\"), $\"a.id\" > $\"b.id\")`. You can also set spark.sql.analyzer.failAmbiguousSelfJoin to false to disable this check."
       },
       "metadata": {
        "errorSummary": "Column datetime_msecs#1419, datetime_msecs#1419 are ambiguous. It's probably because you joined several Datasets together, and some of these Datasets are the same. This column points to one of the Datasets but Spark is unable to figure out which one. Please alias the Datasets with different names via `Dataset.as` before joining them, and specify the column using qualified name, e.g. `df.as(\"a\").join(df.as(\"b\"), $\"a.id\" > $\"b.id\")`. You can also set spark.sql.analyzer.failAmbiguousSelfJoin to false to disable this check."
       },
       "removedWidgets": [],
       "sqlProps": {
        "errorClass": "_LEGACY_ERROR_TEMP_1182",
        "pysparkCallSite": null,
        "pysparkFragment": null,
        "sqlState": null,
        "stackTrace": null,
        "startIndex": null,
        "stopIndex": null
       },
       "stackFrames": [
        "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
        "\u001B[0;31mAnalysisException\u001B[0m                         Traceback (most recent call last)",
        "File \u001B[0;32m<command-1244502079990473>, line 11\u001B[0m\n\u001B[1;32m      8\u001B[0m mouse_movements_alias \u001B[38;5;241m=\u001B[39m mouse_movements\u001B[38;5;241m.\u001B[39malias(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmouse_movements\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     10\u001B[0m \u001B[38;5;66;03m# Perform the join with qualified column names\u001B[39;00m\n\u001B[0;32m---> 11\u001B[0m app_change_mouse_movements \u001B[38;5;241m=\u001B[39m app_change_alias\u001B[38;5;241m.\u001B[39mjoin(\n\u001B[1;32m     12\u001B[0m     mouse_movements_alias,\n\u001B[1;32m     13\u001B[0m     (mouse_movements_alias\u001B[38;5;241m.\u001B[39mdatetime_msecs \u001B[38;5;241m>\u001B[39m\u001B[38;5;241m=\u001B[39m app_change_alias\u001B[38;5;241m.\u001B[39mdatetime_msecs) \u001B[38;5;241m&\u001B[39m\n\u001B[1;32m     14\u001B[0m     (mouse_movements_alias\u001B[38;5;241m.\u001B[39mdatetime_msecs \u001B[38;5;241m<\u001B[39m app_change_alias\u001B[38;5;241m.\u001B[39mend_datetime_msecs),\n\u001B[1;32m     15\u001B[0m     how\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mleft\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     16\u001B[0m )\n\u001B[1;32m     18\u001B[0m display(app_change_mouse_movements)\n",
        "File \u001B[0;32m/databricks/spark/python/pyspark/instrumentation_utils.py:47\u001B[0m, in \u001B[0;36m_wrap_function.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     45\u001B[0m start \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mperf_counter()\n\u001B[1;32m     46\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 47\u001B[0m     res \u001B[38;5;241m=\u001B[39m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m     48\u001B[0m     logger\u001B[38;5;241m.\u001B[39mlog_success(\n\u001B[1;32m     49\u001B[0m         module_name, class_name, function_name, time\u001B[38;5;241m.\u001B[39mperf_counter() \u001B[38;5;241m-\u001B[39m start, signature\n\u001B[1;32m     50\u001B[0m     )\n\u001B[1;32m     51\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m res\n",
        "File \u001B[0;32m/databricks/spark/python/pyspark/sql/dataframe.py:2979\u001B[0m, in \u001B[0;36mDataFrame.join\u001B[0;34m(self, other, on, how)\u001B[0m\n\u001B[1;32m   2977\u001B[0m         on \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jseq([])\n\u001B[1;32m   2978\u001B[0m     \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(how, \u001B[38;5;28mstr\u001B[39m), \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhow should be a string\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m-> 2979\u001B[0m     jdf \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jdf\u001B[38;5;241m.\u001B[39mjoin(other\u001B[38;5;241m.\u001B[39m_jdf, on, how)\n\u001B[1;32m   2980\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m DataFrame(jdf, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msparkSession)\n",
        "File \u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py:1355\u001B[0m, in \u001B[0;36mJavaMember.__call__\u001B[0;34m(self, *args)\u001B[0m\n\u001B[1;32m   1349\u001B[0m command \u001B[38;5;241m=\u001B[39m proto\u001B[38;5;241m.\u001B[39mCALL_COMMAND_NAME \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1350\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcommand_header \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1351\u001B[0m     args_command \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1352\u001B[0m     proto\u001B[38;5;241m.\u001B[39mEND_COMMAND_PART\n\u001B[1;32m   1354\u001B[0m answer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgateway_client\u001B[38;5;241m.\u001B[39msend_command(command)\n\u001B[0;32m-> 1355\u001B[0m return_value \u001B[38;5;241m=\u001B[39m get_return_value(\n\u001B[1;32m   1356\u001B[0m     answer, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgateway_client, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtarget_id, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mname)\n\u001B[1;32m   1358\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m temp_arg \u001B[38;5;129;01min\u001B[39;00m temp_args:\n\u001B[1;32m   1359\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(temp_arg, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_detach\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n",
        "File \u001B[0;32m/databricks/spark/python/pyspark/errors/exceptions/captured.py:261\u001B[0m, in \u001B[0;36mcapture_sql_exception.<locals>.deco\u001B[0;34m(*a, **kw)\u001B[0m\n\u001B[1;32m    257\u001B[0m converted \u001B[38;5;241m=\u001B[39m convert_exception(e\u001B[38;5;241m.\u001B[39mjava_exception)\n\u001B[1;32m    258\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(converted, UnknownException):\n\u001B[1;32m    259\u001B[0m     \u001B[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001B[39;00m\n\u001B[1;32m    260\u001B[0m     \u001B[38;5;66;03m# JVM exception message.\u001B[39;00m\n\u001B[0;32m--> 261\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m converted \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    262\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    263\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m\n",
        "\u001B[0;31mAnalysisException\u001B[0m: Column datetime_msecs#1419, datetime_msecs#1419 are ambiguous. It's probably because you joined several Datasets together, and some of these Datasets are the same. This column points to one of the Datasets but Spark is unable to figure out which one. Please alias the Datasets with different names via `Dataset.as` before joining them, and specify the column using qualified name, e.g. `df.as(\"a\").join(df.as(\"b\"), $\"a.id\" > $\"b.id\")`. You can also set spark.sql.analyzer.failAmbiguousSelfJoin to false to disable this check."
       ],
       "type": "baseError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "app_change = app_change.withColumn(\n",
    "    \"end_datetime_msecs\", \n",
    "    F.lead(\"datetime_msecs\").over(Window.orderBy('timestamp'))\n",
    ")\n",
    "\n",
    "# Alias the DataFrames to avoid ambiguity\n",
    "app_change_alias = app_change.alias(\"app_change\")\n",
    "mouse_movements_alias = mouse_movements.alias(\"mouse_movements\")\n",
    "\n",
    "# Perform the join with qualified column names\n",
    "app_change_mouse_movements = app_change_alias.join(\n",
    "    mouse_movements_alias,\n",
    "    (mouse_movements_alias.datetime_msecs >= app_change_alias.datetime_msecs) &\n",
    "    (mouse_movements_alias.datetime_msecs < app_change_alias.end_datetime_msecs),\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "display(app_change_mouse_movements)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "client": "1"
   },
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Computer Activity Calculations Notebook",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
